{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_tflearn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "C4TL4dCPJsz0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "import tflearn.datasets.mnist as mnist\n",
        "\n",
        "X, y, test_x, test_y = mnist.load_data(one_hot=True)\n",
        "\n",
        "X = X.reshape([-1,28,28,1])\n",
        "test_x = test_x.reshape([-1,28,28,1])\n",
        "\n",
        "convnet = input_data(shape=[None,28,28,1], name='input')\n",
        "\n",
        "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 2)\n",
        "\n",
        "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 2)\n",
        "\n",
        "convnet = fully_connected(convnet, 1024, activation='relu')\n",
        "convnet = dropout(convnet, 0.8)\n",
        "\n",
        "convnet = fully_connected(convnet, 10, activation='softmax')\n",
        "convnet = regression(convnet, optimizer='adam', learning_rate=0.01, loss='categorical_crossentropy', name='targets')\n",
        "\n",
        "model = tflearn.DNN(convnet)\n",
        "\n",
        "model.fit({'input':X},{'targets':y}, n_epoch=10, validation_set=({'input':test_x},{'targets':test_y}), snapshot_step=500, show_metric=True, run_id='mnist')\n",
        "\n",
        "# model.save('tflearn.cnn.model') use to save weights of model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JLr7DlcXUJGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "da0eafd3-7369-40bc-ad68-7adc471743ec"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tflearn\n",
        "\n",
        "# --------------------------------------\n",
        "# High-Level API: Using TFLearn wrappers\n",
        "# --------------------------------------\n",
        "\n",
        "# Using MNIST Dataset\n",
        "import tflearn.datasets.mnist as mnist\n",
        "mnist_data = mnist.read_data_sets(one_hot=True)\n",
        "\n",
        "# User defined placeholders\n",
        "with tf.Graph().as_default():\n",
        "    # Placeholders for data and labels\n",
        "    X = tf.placeholder(shape=(None, 784), dtype=tf.float32)\n",
        "    Y = tf.placeholder(shape=(None, 10), dtype=tf.float32)\n",
        "\n",
        "    net = tf.reshape(X, [-1, 28, 28, 1])\n",
        "\n",
        "    # Using TFLearn wrappers for network building\n",
        "    net = tflearn.conv_2d(net, 32, 3, activation='relu')\n",
        "    net = tflearn.max_pool_2d(net, 2)\n",
        "    net = tflearn.local_response_normalization(net)\n",
        "    net = tflearn.dropout(net, 0.8)\n",
        "    net = tflearn.conv_2d(net, 64, 3, activation='relu')\n",
        "    net = tflearn.max_pool_2d(net, 2)\n",
        "    net = tflearn.local_response_normalization(net)\n",
        "    net = tflearn.dropout(net, 0.8)\n",
        "    net = tflearn.fully_connected(net, 128, activation='tanh')\n",
        "    net = tflearn.dropout(net, 0.8)\n",
        "    net = tflearn.fully_connected(net, 256, activation='tanh')\n",
        "    net = tflearn.dropout(net, 0.8)\n",
        "    net = tflearn.fully_connected(net, 10, activation='linear')\n",
        "\n",
        "    # Defining other ops using Tensorflow\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=net, labels=Y))\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)\n",
        "\n",
        "    # Initializing the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Launch the graph\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "\n",
        "        batch_size = 128\n",
        "        for epoch in range(2):  # 2 epochs\n",
        "            avg_cost = 0.\n",
        "            total_batch = int(mnist_data.train.num_examples / batch_size)\n",
        "            for i in range(total_batch):\n",
        "                batch_xs, batch_ys = mnist_data.train.next_batch(batch_size)\n",
        "                sess.run(optimizer, feed_dict={X: batch_xs, Y: batch_ys})\n",
        "                cost = sess.run(loss, feed_dict={X: batch_xs, Y: batch_ys})\n",
        "                avg_cost += cost / total_batch\n",
        "                if i % 20 == 0:\n",
        "                    print(\"Epoch:\", '%03d' % (epoch + 1), \"Step:\", '%03d' % i,\n",
        "                          \"Loss:\", str(cost))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist/train-images-idx3-ubyte.gz\n",
            "Extracting mnist/train-labels-idx1-ubyte.gz\n",
            "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
            "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
            "('Epoch:', '001', 'Step:', '000', 'Loss:', '2.1637354')\n",
            "('Epoch:', '001', 'Step:', '020', 'Loss:', '0.35656413')\n",
            "('Epoch:', '001', 'Step:', '040', 'Loss:', '0.23612629')\n",
            "('Epoch:', '001', 'Step:', '060', 'Loss:', '0.119291626')\n",
            "('Epoch:', '001', 'Step:', '080', 'Loss:', '0.077329636')\n",
            "('Epoch:', '001', 'Step:', '100', 'Loss:', '0.2571221')\n",
            "('Epoch:', '001', 'Step:', '120', 'Loss:', '0.062105387')\n",
            "('Epoch:', '001', 'Step:', '140', 'Loss:', '0.058997795')\n",
            "('Epoch:', '001', 'Step:', '160', 'Loss:', '0.123600885')\n",
            "('Epoch:', '001', 'Step:', '180', 'Loss:', '0.030033998')\n",
            "('Epoch:', '001', 'Step:', '200', 'Loss:', '0.11691041')\n",
            "('Epoch:', '001', 'Step:', '220', 'Loss:', '0.0719111')\n",
            "('Epoch:', '001', 'Step:', '240', 'Loss:', '0.03419916')\n",
            "('Epoch:', '001', 'Step:', '260', 'Loss:', '0.031557117')\n",
            "('Epoch:', '001', 'Step:', '280', 'Loss:', '0.019852277')\n",
            "('Epoch:', '001', 'Step:', '300', 'Loss:', '0.0853085')\n",
            "('Epoch:', '001', 'Step:', '320', 'Loss:', '0.041292913')\n",
            "('Epoch:', '001', 'Step:', '340', 'Loss:', '0.08117339')\n",
            "('Epoch:', '001', 'Step:', '360', 'Loss:', '0.090861544')\n",
            "('Epoch:', '001', 'Step:', '380', 'Loss:', '0.06744135')\n",
            "('Epoch:', '001', 'Step:', '400', 'Loss:', '0.080372296')\n",
            "('Epoch:', '001', 'Step:', '420', 'Loss:', '0.029081838')\n",
            "('Epoch:', '002', 'Step:', '000', 'Loss:', '0.054723706')\n",
            "('Epoch:', '002', 'Step:', '020', 'Loss:', '0.043678693')\n",
            "('Epoch:', '002', 'Step:', '040', 'Loss:', '0.105126426')\n",
            "('Epoch:', '002', 'Step:', '060', 'Loss:', '0.0070076324')\n",
            "('Epoch:', '002', 'Step:', '080', 'Loss:', '0.023423888')\n",
            "('Epoch:', '002', 'Step:', '100', 'Loss:', '0.01936814')\n",
            "('Epoch:', '002', 'Step:', '120', 'Loss:', '0.060123812')\n",
            "('Epoch:', '002', 'Step:', '140', 'Loss:', '0.0560347')\n",
            "('Epoch:', '002', 'Step:', '160', 'Loss:', '0.04795142')\n",
            "('Epoch:', '002', 'Step:', '180', 'Loss:', '0.039360214')\n",
            "('Epoch:', '002', 'Step:', '200', 'Loss:', '0.059310846')\n",
            "('Epoch:', '002', 'Step:', '220', 'Loss:', '0.019963434')\n",
            "('Epoch:', '002', 'Step:', '240', 'Loss:', '0.01700061')\n",
            "('Epoch:', '002', 'Step:', '260', 'Loss:', '0.07388508')\n",
            "('Epoch:', '002', 'Step:', '280', 'Loss:', '0.07168507')\n",
            "('Epoch:', '002', 'Step:', '300', 'Loss:', '0.0054659517')\n",
            "('Epoch:', '002', 'Step:', '320', 'Loss:', '0.046801277')\n",
            "('Epoch:', '002', 'Step:', '340', 'Loss:', '0.07244796')\n",
            "('Epoch:', '002', 'Step:', '360', 'Loss:', '0.012452754')\n",
            "('Epoch:', '002', 'Step:', '380', 'Loss:', '0.013204571')\n",
            "('Epoch:', '002', 'Step:', '400', 'Loss:', '0.082273066')\n",
            "('Epoch:', '002', 'Step:', '420', 'Loss:', '0.031853072')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}