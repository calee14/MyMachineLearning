{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetworkModel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "-6MWI0OdEn0c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# What this script does\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "input > weight > hidden layer 1 (activation function) > weights > hidden layer 2 (activation function) > weights > output layer\n",
        "\n",
        "compare output ot intended output > cost function (cross entropy) optimization function (optimizer) > minimize cost ( AdamOptimizer....SGD, AdaGrad)\n",
        "\n",
        "backpropagation\n",
        "\n",
        "feed foward + backprop = epoch\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "P4Sx8buYEEw0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B2dZFLsaHwCr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classes in Mnist Data\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Ten classes, 0-9\n",
        "\n",
        "\n",
        "```\n",
        "0 = 0\n",
        "1 = 1\n",
        "2 = 2\n",
        "3 = 3\n",
        "```\n",
        "## Actually it equates to:\n",
        "\n",
        "\n",
        "```\n",
        "0 = [1,0,0,0,0,0,0,0,0,0] # 1's repsent if the pixel is hot or in other words on.\n",
        "1 = [0,1,0,0,0,0,0,0,0,0]\n",
        "2 = [0,0,1,0,0,0,0,0,0,0]\n",
        "3 = [1,0,0,1,0,0,0,0,0,0]\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "igtSS_UBJOkl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets('/tmp/data/', one_hot=True)\n",
        "\n",
        "n_nodes_hl1 = 500\n",
        "n_nodes_hl2 = 500\n",
        "n_nodes_hl3 = 500\n",
        "\n",
        "n_classes = 10\n",
        "batch_size = 100\n",
        "\n",
        "# matrix is height by width\n",
        "# height x width\n",
        "# flat/squash to 784 values; turning into string of values\n",
        "# x is data, y is label\n",
        "x = tf.placeholder('float', [None, 784])\n",
        "y = tf.placeholder('float')\n",
        "\n",
        "def neural_network_model(data):\n",
        "  \n",
        "  # create the variables for the layers\n",
        "  \n",
        "  hidden_1_layer = {'weights':tf.Variable(tf.random_normal([784, n_nodes_hl1])),\n",
        "                   'biases':tf.Variable(tf.random_normal(n_nodes_hl1))}\n",
        "  \n",
        "  hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
        "                   'biases':tf.Variable(tf.random_normal(n_nodes_hl2))}\n",
        "  \n",
        "  hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
        "                   'biases':tf.Variable(tf.random_normal(n_nodes_hl3))}\n",
        "  \n",
        "  output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
        "                   'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
        "  \n",
        "  # (input data * weights) + biases - model for each layer\n",
        "  \n",
        "  l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']) + hidden_1_layer['biases'])\n",
        "  l1 = tf.nn.relu(l1) # .relu is activation function\n",
        "  \n",
        "  l2 = tf.add(tf.matmul(l1, hidden_2_layer['weights']) + hidden_2_layer['biases'])\n",
        "  l2 = tf.nn.relu(l2) # .relu is activation function\n",
        "  \n",
        "  l3 = tf.add(tf.matmul(l2, hidden_3_layer['weights']) + hidden_3_layer['biases'])\n",
        "  l3 = tf.nn.relu(l3) # .relu is activation function\n",
        "  \n",
        "  output = tf.matmul(l3, output_layer['weights']) + output_layer['biases']\n",
        "  \n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}