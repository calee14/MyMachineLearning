{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6MWI0OdEn0c",
    "colab_type": "text"
   },
   "source": [
    "# What this script does\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "input > weight > hidden layer 1 (activation function) > weights > hidden layer 2 (activation function) > weights > output layer\n",
    "\n",
    "compare output ot intended output > cost function (cross entropy) optimization function (optimizer) > minimize cost ( AdamOptimizer....SGD, AdaGrad)\n",
    "\n",
    "backpropagation\n",
    "\n",
    "feed foward + backprop = epoch\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "P4Sx8buYEEw0",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2dZFLsaHwCr",
    "colab_type": "text"
   },
   "source": [
    "# Classes in Mnist Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Ten classes, 0-9\n",
    "\n",
    "\n",
    "```\n",
    "0 = 0\n",
    "1 = 1\n",
    "2 = 2\n",
    "3 = 3\n",
    "```\n",
    "## Actually it equates to:\n",
    "\n",
    "\n",
    "```\n",
    "0 = [1,0,0,0,0,0,0,0,0,0] # 1's repsent if the pixel is hot or in other words on.\n",
    "1 = [0,1,0,0,0,0,0,0,0,0]\n",
    "2 = [0,0,1,0,0,0,0,0,0,0]\n",
    "3 = [1,0,0,1,0,0,0,0,0,0]\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "igtSS_UBJOkl",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85.0
    },
    "outputId": "d53089e7-4fc1-446a-edea-bb18e098ff68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('/tmp/data/', one_hot=True)\n",
    "\n",
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500\n",
    "\n",
    "n_classes = 10\n",
    "batch_size = 100\n",
    "\n",
    "# matrix is height by width\n",
    "# height x width\n",
    "# flat/squash to 784 values; turning into string of values\n",
    "# x is data, y is label\n",
    "x = tf.placeholder('float', [None, 784])\n",
    "y = tf.placeholder('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_OVWuP4vR7z",
    "colab_type": "text"
   },
   "source": [
    "# The Model\n",
    "\n",
    "\n",
    "---\n",
    "Building the computation graph of tensor flow model and the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "w1Ncr1e-vbcR",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def neural_network_model(data):\n",
    "  \n",
    "    # create the variables for the layers\n",
    "    \n",
    "    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([784, n_nodes_hl1])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "    hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "\n",
    "    hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "\n",
    "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
    "                    'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    # (input data * weights) + biases - model for each layer\n",
    "    \n",
    "    l1 = tf.add(tf.matmul(data,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu(l1) # .relu is activation function\n",
    "\n",
    "    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu(l2) # .relu is activation function\n",
    "\n",
    "    l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.relu(l3) # .relu is activation function\n",
    "\n",
    "    output = tf.matmul(l3,output_layer['weights']) + output_layer['biases']\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jql6zTCUvj5b",
    "colab_type": "text"
   },
   "source": [
    "# Training the Model\n",
    "\n",
    "---\n",
    "\n",
    "Specify what to run through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "-5tCCEDEv2be",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204.0
    },
    "outputId": "cd2e2970-5666-4842-d161-63da0e5b7386"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 10 loss: 1935058.148284912\n",
      "Epoch 1 completed out of 10 loss: 402867.47800827026\n",
      "Epoch 2 completed out of 10 loss: 213101.25807976723\n",
      "Epoch 3 completed out of 10 loss: 128181.90613675117\n",
      "Epoch 4 completed out of 10 loss: 77189.83758546412\n",
      "Epoch 5 completed out of 10 loss: 48890.68161687968\n",
      "Epoch 6 completed out of 10 loss: 32051.227833879442\n",
      "Epoch 7 completed out of 10 loss: 25532.522573613845\n",
      "Epoch 8 completed out of 10 loss: 20699.310237876176\n",
      "Epoch 9 completed out of 10 loss: 15710.198667769173\n",
      "Accuracy: 0.9497\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(x):\n",
    "  prediction = neural_network_model(x)\n",
    "  cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y) )\n",
    "  optimizer = tf.train.AdamOptimizer().minimize(cost) # minimizes cost\n",
    "  \n",
    "  # cycles of feed foward + backprop (fixing weights)\n",
    "  hm_epochs = 10\n",
    "  \n",
    "  with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    \n",
    "    # train network\n",
    "    for epoch in range(hm_epochs):\n",
    "      epoch_loss = 0\n",
    "      for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "        epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([optimizer, cost], feed_dict = {x: epoch_x, y: epoch_y})\n",
    "        epoch_loss += c\n",
    "      print('Epoch', epoch, 'completed out of', hm_epochs, 'loss:', epoch_loss)\n",
    "    \n",
    "    # once optimized weights\n",
    "    # run them through model\n",
    "    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "    \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "    \n",
    "    print('Accuracy:', accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n",
    "  \n",
    "\n",
    "train_neural_network(x)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "NeuralNetworkModel.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
